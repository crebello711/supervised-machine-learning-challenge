{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I predict that logistic regression would perform better because in the context of low-dimensional data that we have here (i.e. when the number of covariates is small compared to the sample size), logistic regression is considered a standard approach for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  loan_status  \n",
       "0                 1       22800            0  \n",
       "1                 0       13600            0  \n",
       "2                 0       16100            0  \n",
       "3                 1       22700            0  \n",
       "4                 1       23000            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "lending_df = pd.read_csv('resources/lending_data.csv')\n",
    "lending_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  \n",
       "0                 1       22800  \n",
       "1                 0       13600  \n",
       "2                 0       16100  \n",
       "3                 1       22700  \n",
       "4                 1       23000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = lending_df['loan_status'].values\n",
    "X = lending_df.drop('loan_status', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9921240885954051\n",
      "Testing Data Score: 0.9918489475856377\n"
     ]
    }
   ],
   "source": [
    "#Fit (train) our model by using the training data\n",
    "logistic_regression=classifier.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {logistic_regression.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {logistic_regression.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18663,   102],\n",
       "       [   56,   563]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = classifier.predict(X_test)\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74657,   379],\n",
       "       [  237,  2263]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, classifier.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18765\n",
      "           1       0.85      0.91      0.88       619\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.92      0.95      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The precision is 85% and sensitivity is 91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910751134956666"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "#Scale the data and then fit \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9975409272252029\n",
      "Testing Score: 0.9917457697069748\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {rf_classifier.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {rf_classifier.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.29066792e-01 2.74137485e-01 1.74521675e-01 1.58682971e-01\n",
      " 1.18902531e-01 8.06639163e-05 1.44607881e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAPQElEQVR4nO3df6zdd13H8eeLlg0FgUFvDGkLLVINVcxKLiVmcRrZRgmk5Y8ROoMZZkmjYQazGFMk2WL5Z0Ci/DN1DauZCJaxQXIjxbmw4Y+QQW+3AbajcqlzvSlmFzvRCW7p9vaP+9WcHk57v929t+fez56P5Kbn++vcd5vmeb/9nnO+TVUhSWrXi8Y9gCRpeRl6SWqcoZekxhl6SWqcoZekxq0d9wDD1q1bV5s2bRr3GJK0qhw5cuT7VTUxatuKC/2mTZuYnp4e9xiStKok+ddzbfPSjSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1bsV9MvaFZtPeL457hLM8dus7xz2CpCXmGb0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1LjeoU+yY4kx5PMJNk7YvtNSY4l+WaSLyd53cC2Z5M80n1NLeXwkqSFLXg/+iRrgNuAq4FZ4HCSqao6NrDbw8BkVf0wyW8DHwPe2237UVVdvsRzS5J66nNGvx2YqaoTVfUMcBDYNbhDVT1QVT/sFh8ENiztmJKk56tP6NcDJweWZ7t153ID8KWB5ZckmU7yYJJ3jzogyZ5un+m5ubkeI0mS+urzXwlmxLoauWPyPmAS+JWB1a+tqlNJXg/cn+RbVfXds56saj+wH2BycnLkc0uSnp8+Z/SzwMaB5Q3AqeGdklwFfBjYWVVP/9/6qjrV/XoC+AqwbRHzSpIuUJ/QHwa2JNmc5BJgN3DWu2eSbANuZz7yTwysvyzJpd3jdcAVwOCLuJKkZbbgpZuqOpPkRuBeYA1woKqOJtkHTFfVFPBx4GXA55IAPF5VO4E3ArcneY75Hyq3Dr1bR5K0zPpco6eqDgGHhtbdPPD4qnMc91XgTYsZUJK0OH4yVpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIaZ+glqXGGXpIa1yv0SXYkOZ5kJsneEdtvSnIsyTeTfDnJ6wa2XZ/kO93X9Us5vCRpYQuGPska4DbgHcBW4LokW4d2exiYrKpfBO4GPtYd+yrgFuCtwHbgliSXLd34kqSF9Dmj3w7MVNWJqnoGOAjsGtyhqh6oqh92iw8CG7rHbwfuq6rTVfUkcB+wY2lGlyT10Sf064GTA8uz3bpzuQH40oUcm2RPkukk03Nzcz1GkiT11Sf0GbGuRu6YvA+YBD5+IcdW1f6qmqyqyYmJiR4jSZL66hP6WWDjwPIG4NTwTkmuAj4M7Kyqpy/kWEnS8ukT+sPAliSbk1wC7AamBndIsg24nfnIPzGw6V7gmiSXdS/CXtOtkyRdJGsX2qGqziS5kflArwEOVNXRJPuA6aqaYv5SzcuAzyUBeLyqdlbV6SQfYf6HBcC+qjq9LL8TSdJIC4YeoKoOAYeG1t088Piq8xx7ADjwfAeUJC2On4yVpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMYZeklqnKGXpMb1unulNGjT3i+Oe4SzPHbrO8c9grSieUYvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY3zXjd6QfD+PHoh84xekhpn6CWpcb1Cn2RHkuNJZpLsHbH9yiQPJTmT5Nqhbc8meaT7mlqqwSVJ/Sx4jT7JGuA24GpgFjicZKqqjg3s9jjwfuD3RjzFj6rq8iWYVZL0PPR5MXY7MFNVJwCSHAR2Af8f+qp6rNv23DLMKElahD6XbtYDJweWZ7t1fb0kyXSSB5O8e9QOSfZ0+0zPzc1dwFNLkhbSJ/QZsa4u4Hu8tqomgV8HPpHkZ37syar2V9VkVU1OTExcwFNLkhbSJ/SzwMaB5Q3Aqb7foKpOdb+eAL4CbLuA+SRJi9Qn9IeBLUk2J7kE2A30evdMksuSXNo9XgdcwcC1fUnS8lsw9FV1BrgRuBd4FLirqo4m2ZdkJ0CStySZBd4D3J7kaHf4G4HpJN8AHgBuHXq3jiRpmfW6BUJVHQIODa27eeDxYeYv6Qwf91XgTYucUZKWxQvl1hh+MlaSGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxhl6SGmfoJalxvW6BsJqspI80L9fHmSXpQnhGL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNa+599FIrVtJnQsDPhaxmntFLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1ztBLUuMMvSQ1rlfok+xIcjzJTJK9I7ZfmeShJGeSXDu07fok3+m+rl+qwSVJ/SwY+iRrgNuAdwBbgeuSbB3a7XHg/cBnho59FXAL8FZgO3BLkssWP7Ykqa8+Z/TbgZmqOlFVzwAHgV2DO1TVY1X1TeC5oWPfDtxXVaer6kngPmDHEswtSeqpT+jXAycHlme7dX30OjbJniTTSabn5uZ6PrUkqY8+oc+IddXz+XsdW1X7q2qyqiYnJiZ6PrUkqY8+oZ8FNg4sbwBO9Xz+xRwrSVoCfUJ/GNiSZHOSS4DdwFTP578XuCbJZd2LsNd06yRJF8mCoa+qM8CNzAf6UeCuqjqaZF+SnQBJ3pJkFngPcHuSo92xp4GPMP/D4jCwr1snSbpIev1XglV1CDg0tO7mgceHmb8sM+rYA8CBRcwoSVoEPxkrSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY0z9JLUOEMvSY3rFfokO5IcTzKTZO+I7Zcm+Wy3/WtJNnXrNyX5UZJHuq8/W9rxJUkLWbvQDknWALcBVwOzwOEkU1V1bGC3G4Anq+oNSXYDHwXe2237blVdvsRzS5J66nNGvx2YqaoTVfUMcBDYNbTPLuDO7vHdwNuSZOnGlCQ9X31Cvx44ObA8260buU9VnQF+ALy627Y5ycNJ/i7JL4/6Bkn2JJlOMj03N3dBvwFJ0vn1Cf2oM/Pquc/3gNdW1TbgJuAzSV7+YztW7a+qyaqanJiY6DGSJKmvPqGfBTYOLG8ATp1rnyRrgVcAp6vq6ar6d4CqOgJ8F/jZxQ4tSeqvT+gPA1uSbE5yCbAbmBraZwq4vnt8LXB/VVWSie7FXJK8HtgCnFia0SVJfSz4rpuqOpPkRuBeYA1woKqOJtkHTFfVFHAH8KkkM8Bp5n8YAFwJ7EtyBngW+K2qOr0cvxFJ0mgLhh6gqg4Bh4bW3Tzw+H+A94w47h7gnkXOKElaBD8ZK0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mNM/SS1DhDL0mN6xX6JDuSHE8yk2TviO2XJvlst/1rSTYNbPtQt/54krcv3eiSpD4WDH2SNcBtwDuArcB1SbYO7XYD8GRVvQH4Y+Cj3bFbgd3AzwM7gD/pnk+SdJH0OaPfDsxU1YmqegY4COwa2mcXcGf3+G7gbUnSrT9YVU9X1b8AM93zSZIukrU99lkPnBxYngXeeq59qupMkh8Ar+7WPzh07Prhb5BkD7CnW3wqyfFe0y+vdcD3F/ME+egSTdLPoucFZ+7BmZffksx7ka2EP+PXnWtDn9BnxLrquU+fY6mq/cD+HrNcNEmmq2py3HP0tdrmBWe+WFbbzKttXlj5M/e5dDMLbBxY3gCcOtc+SdYCrwBO9zxWkrSM+oT+MLAlyeYklzD/4urU0D5TwPXd42uB+6uquvW7u3flbAa2AF9fmtElSX0seOmmu+Z+I3AvsAY4UFVHk+wDpqtqCrgD+FSSGebP5Hd3xx5NchdwDDgDfKCqnl2m38tSW1GXknpYbfOCM18sq23m1TYvrPCZM3/iLUlqlZ+MlaTGGXpJapyhH7LQ7R5WmiQHkjyR5J/GPUtfSTYmeSDJo0mOJvnguGc6nyQvSfL1JN/o5v3Dcc/UV5I1SR5O8tfjnqWPJI8l+VaSR5JMj3uePpK8MsndSb7d/Z3+pXHPNMxr9AO62zP8M3A1828NPQxcV1XHxjrYeSS5EngK+Iuq+oVxz9NHktcAr6mqh5L8FHAEePdK/XPuPuX90qp6KsmLgX8EPlhVDy5w6NgluQmYBF5eVe8a9zwLSfIYMFlVq+YDU0nuBP6hqj7ZvTPxJ6vqP8Y91yDP6M/W53YPK0pV/T3z73RaNarqe1X1UPf4v4BHGfGJ6ZWi5j3VLb64+1rxZ0hJNgDvBD457llaleTlwJXMv/OQqnpmpUUeDP2wUbd7WLEBakF3p9NtwNfGO8n5dZdAHgGeAO6rqhU9b+cTwO8Dz417kAtQwN8mOdLdGmWlez0wB/x5d4nsk0leOu6hhhn6s/W6ZYOWRpKXAfcAv1tV/znuec6nqp6tqsuZ/3T39iQr+jJZkncBT1TVkXHPcoGuqKo3M3+33A90lyZXsrXAm4E/raptwH8DK+61PUN/Nm/ZcJF017rvAT5dVZ8f9zx9df8s/wrzt91eya4AdnbXvA8Cv5bkL8c70sKq6lT36xPAF1j5d7udBWYH/oV3N/PhX1EM/dn63O5Bi9S9uHkH8GhV/dG451lIkokkr+we/wRwFfDt8U51flX1oaraUFWbmP97fH9VvW/MY51Xkpd2L87TXf64BljR7yarqn8DTib5uW7V25i/E8CK0ufulS8Y57rdw5jHOq8kfwX8KrAuySxwS1XdMd6pFnQF8BvAt7rr3gB/UFWHxjjT+bwGuLN7V9aLgLuqalW8XXGV+WngC/PnAawFPlNVfzPekXr5HeDT3cnhCeA3xzzPj/HtlZLUOC/dSFLjDL0kNc7QS1LjDL0kNc7QS1LjDL0kNc7QS1Lj/hetsirkHlibFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = rf_classifier.feature_importances_\n",
    "print(features)\n",
    "plt.bar(x = range(len(features)), height=features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False, False,  True])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = SelectFromModel(rf_classifier)\n",
    "sel.fit(X_train_scaled, y_train)\n",
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X), y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9942908240473243\n",
      "Testing Score: 0.9936545604622369\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "print(f'Training Score: {rf_classifier.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {rf_classifier.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After testing the two models ,it makes sense that logistic regression presents a higher level of accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
